{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clustering by Root\n",
    "\n",
    "Given a corpus of words extracted from texts, we may wish to cluster the words by their root stem. In order to do this, we must first remove the root stem.\n",
    "\n",
    "I am using a corpus of words scraped from [childrens stories](latvian/books/pasakas.net.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reiz', 'viena', 'meita', 'gājusi', 'pa', 'ceļu', 'pa', 'priekšu', 'gājis', 'vecs', 'vecis', 'kas', 'tikko', 'varējis', 'pavazāt', 'kājas', 'vecais', 'tēv', 'sēdi', 'man']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "with open(\"library.json\") as f:\n",
    "    text = ' '.join(\n",
    "        book[\"text\"]\n",
    "        for title, book in json.loads(f.read()).items()\n",
    "    )\n",
    "    words = list(map(str.lower, re.findall(r'[^\\W\\d]+', text)))\n",
    "\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infinite parameter model\n",
    "\n",
    "This was a rough hack that I am formalizing so that improvements can more easily be made.\n",
    "\n",
    "Let us assume that a word is made of a prefix, stem and suffix. Each can vary in length, but the obvious order is constrained. Using our corpus of text, we can easily compute the probability of any prefix, stem and suffix. so given cut locations $ c_{prefix}, c_{suffix} $, we can compute the probability of the associated prefix, stem and suffix word the *i*th word (respectively $ P_i, T_i, S_i $).\n",
    "\n",
    "$$\\begin{align}\n",
    "Pr(P_i, T_i, S_i ; \\vec{c}_i)\n",
    "\\end{align}$$\n",
    "\n",
    "We wish to optimized the log-likelihood of the parameters $ \\{ \\vec{c}_i \\}_i $. Fortunately in this kind of stupid model, there is no limit on the parameters because we do it per word, so the log-likelihood factors easily and we can simply optimize per word.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\vec{c} &= \\text{arg max}_{\\vec{c}} \\sum_i \\log Pr(P_i, T_i, S_i ; \\vec{c}_i) \\\\\n",
    "\\vec{c}_i &= \\text{arg max}_{\\vec{c}_i} \\log Pr(P_i, T_i, S_i ; \\vec{c}_i)\n",
    "\\end{align}$$\n",
    "\n",
    "Clearly, a reduced parameter model could have benefits, but this was easy to program for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('mācīt', 'āj', 's'), -49.39630998974996, 5, 7)\n",
      "(('no', 'nes', 'īšot'), -58.99538681815128, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "def loglikelihood(word, words, p_cut, s_cut):\n",
    "    Pr = np.sum([\n",
    "        np.array([\n",
    "            word[:p_cut] == w[:p_cut],\n",
    "            word[p_cut:s_cut] in w,\n",
    "            word[s_cut:] == w[s_cut:]\n",
    "        ])\n",
    "        for w in words\n",
    "    ], axis=0)/len(words)\n",
    "    L = np.array([p_cut, s_cut - p_cut, len(word) - s_cut])\n",
    "    return np.log(Pr).dot(L), (word[:p_cut], word[p_cut:s_cut], word[s_cut:])\n",
    "\n",
    "def max_ll(word, words):\n",
    "    l_min, conf = -np.inf, None\n",
    "    p_min, s_min = None, None\n",
    "    for p_cut in range(len(word)):\n",
    "        for s_cut in range(p_cut, len(word)):\n",
    "            ll, cuts = loglikelihood(word, words, p_cut, s_cut)\n",
    "            if ll > l_min:\n",
    "                l_min, conf, p_min, s_min = ll, cuts, p_cut, s_cut\n",
    "    return conf, l_min, p_min, s_min\n",
    "\n",
    "print(max_ll('mācītājs', words))\n",
    "print(max_ll('nonesīšot', words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool! It actually seems to work fairly well. Pretty good for a rough hack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
